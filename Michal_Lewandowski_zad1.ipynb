{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a56abf-2af9-49cd-beb4-4167fce93171",
   "metadata": {},
   "source": [
    "# Project 1 MichaÅ‚ Lewandowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c7192-c7f8-43ec-8ea0-4a391b9a17a5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8e38e-6ac4-4d89-b1ef-ff5c9e5c2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, lognorm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, root_mean_squared_error, silhouette_score, silhouette_samples, calinski_harabasz_score\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c4bf2-7a82-42ec-bb20-87ad2af18814",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f249eb-df52-4459-a770-b819d94e43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_short_classification_report(y_true, y_pred):\n",
    "    print('accuracy', accuracy_score(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print('confusion matrix')\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b2034-3197-4791-a450-abc69ebe0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importance(feature_importances, column_labels, std=None):\n",
    "    # model has to be trained first\n",
    "    plt.barh(column_labels, feature_importances, xerr=std)\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f073f-cb33-4c3a-8944-bac0c53e86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df, width=15, height=12):\n",
    "    correlation_matrix = df.corr()\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='vlag', fmt=\".2f\", linewidths=0.5)\n",
    "    \n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a5d78-4b89-4f62-b698-21073fa0a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_KMeans(data, i):\n",
    "    km = KMeans(n_clusters=i,random_state=0,n_init=\"auto\").fit(data)\n",
    "    print(f\"{i} clusters silhouette: {silhouette_score(data, km.labels_)}, CH score: {calinski_harabasz_score(data, km.labels_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f258c0c-de8d-4613-88c6-827c9bfdb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_GMM(data, i, covariance_type='full'):\n",
    "    gmm = GaussianMixture(n_components=i,random_state=0,n_init=5, covariance_type=covariance_type).fit(data)\n",
    "    labels = gmm.predict(data)\n",
    "    print(f\"{i} clusters silhouette: {silhouette_score(data, labels)}, CH score: {calinski_harabasz_score(data, labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e58931-99b8-42b8-ae50-af3f6895d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_plots_GMM(X, min_cl, max_cl, figsize_x=15, figsize_y=6):\n",
    "    GAP_BETWEEN_SILHOUETTES = 10\n",
    "    for n_clusters in range(min_cl, max_cl + 1):\n",
    "        fig, ax1 = plt.subplots(1, 1)\n",
    "        fig.set_size_inches(figsize_x, figsize_y)\n",
    "\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * GAP_BETWEEN_SILHOUETTES])\n",
    "\n",
    "        gmm = GaussianMixture(n_components=n_clusters,random_state=0,n_init=5, covariance_type='spherical')\n",
    "        cluster_labels = gmm.fit_predict(X)\n",
    "\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        print(\n",
    "            \"For n_clusters =\",\n",
    "            n_clusters,\n",
    "            \"The average silhouette_score is :\",\n",
    "            silhouette_avg,\n",
    "        )\n",
    "\n",
    "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "        y_lower = GAP_BETWEEN_SILHOUETTES\n",
    "        for i in range(n_clusters):\n",
    "            i_th_scores = sample_silhouette_values[cluster_labels == i]\n",
    "            i_th_scores.sort()\n",
    "\n",
    "            i_th_size = i_th_scores.shape[0]\n",
    "            y_upper = y_lower + i_th_size\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(\n",
    "                np.arange(y_lower, y_upper),\n",
    "                0, \n",
    "                i_th_scores,\n",
    "                facecolor=color,\n",
    "                edgecolor=color,\n",
    "                alpha=0.7\n",
    "            )\n",
    "            ax1.text(-0.05, y_lower + 0.5 * i_th_size, str(i))\n",
    "            y_lower = y_upper + GAP_BETWEEN_SILHOUETTES\n",
    "\n",
    "        ax1.axvline(silhouette_avg, color='red', linestyle='--')\n",
    "\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac4136-3076-4f51-a04e-46e31eb12c52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 1. Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba179c3-20d2-4876-8ee0-d5b81bb35a51",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3450c4-3b1f-47ba-a92c-c168bee53034",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"earnings.csv\", sep=\";\")\n",
    "data = raw_data.drop(columns=\"id\")\n",
    "print(\"Total number of observations:\", len(raw_data))\n",
    "print(\"Total number of columns:\", len(raw_data.columns))\n",
    "print(\"Total number of features:\", len(data.columns))\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf05bf-9bf4-4e4a-a308-1322b441fc45",
   "metadata": {},
   "source": [
    "### How many quantitative and how many qualitative variables do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338a72f-09af-4006-9622-74aad58469cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for id, col in enumerate(raw_data.columns):\n",
    "    print(col, ':', pd.unique(raw_data.iloc[:, id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35353b9-ba19-4a54-92d4-2b7757c447f5",
   "metadata": {},
   "source": [
    "| Quantitative      | Qualitative |\n",
    "| ----------------- | ----------- |\n",
    "| base              | sector      |\n",
    "| bonus             | section_07  |\n",
    "| overtime_pay      | sex         |\n",
    "| other             | education   |\n",
    "| age               | contract    |\n",
    "| duration_total    |             |\n",
    "| duration_entity   |             |\n",
    "| duration_nominal  |             |\n",
    "| duration_overtime |             |\n",
    "\n",
    "There is 9 quantitative and 5 qualitative variables. \\\n",
    "Dataset contains 11000 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24299370-1a37-4cd7-aacf-f7ad6e900909",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative = ['sector', 'section_07', 'sex', 'education', 'contract']\n",
    "quantitative = data.columns.drop(qualitative).astype(str).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7f479-d9b7-498a-aaa2-a915483e7d63",
   "metadata": {},
   "source": [
    "### Are there any missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e11e-25a7-467b-8c92-5c620cd84838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b7bd9-47ed-4341-8706-725a29437a6f",
   "metadata": {},
   "source": [
    "There is no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7e3a0-4ba8-47cf-af79-a8ec4d7be18b",
   "metadata": {},
   "source": [
    "### Provide and describe appropriate frequency tables or descriptive statistics for the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f8836-470e-4700-baed-6dd89a97c0a6",
   "metadata": {},
   "source": [
    "#### Quantitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a0ec4-55ec-4614-b695-359e5c4752e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[quantitative].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1731f4c-35cb-483e-9dbc-66dcb887d813",
   "metadata": {},
   "source": [
    "#### Qualitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112f93f-e8db-448c-acb8-2f430abd4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = {}\n",
    "map['sector'] = {1: 'public', 2: 'private'}\n",
    "map['section_07'] = {1: 'Public Administration and Defence; Compulsory Social Security', 2: 'Education', 3: 'Human Health and Social Work Activities'}\n",
    "map['sex'] = {1: 'man', 2: 'woman'}\n",
    "map['education'] = {1: 'doctorate', 2: 'higher', 3: 'post-secondary', 4: 'secondary', 5: 'basic vocational', 6: 'middle school and below'}\n",
    "map['contract'] = {1: 'for an indefinite period', 2: 'for a definite period'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862cdcf-3e35-4768-b7d7-6ddad2f5736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in qualitative:\n",
    "    tmp = data[col]\n",
    "    res = tmp.map(map[col])\n",
    "    print(res.value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95cc03-3956-4da7-af82-c73e0be0845f",
   "metadata": {},
   "source": [
    "### Present and discuss (where appropriate) variablesâ€™ distributions, e.g. compare them with the normal, or other distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d9382-fb30-4740-b6b4-673114440e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = len(quantitative)\n",
    "fig, axes = plt.subplots(n_rows := n_cols, 1, figsize=(7, 0.7 * n_rows), sharex=False)\n",
    "if n_cols == 1:\n",
    "    axes = [axes]\n",
    "for ax, col in zip(axes, quantitative):\n",
    "    ax.plot(data[col], [0] * len(data[col]), '|', markersize=30, color='black')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(min(data[col]), max(data[col]))\n",
    "    ax.set_title(col, fontsize=8, pad=2)\n",
    "    ax.tick_params(axis='x', labelsize=7)\n",
    "    ax.grid(True, axis='x', linestyle='--', alpha=0.4)\n",
    "plt.subplots_adjust(hspace=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc1cd9-1362-4db4-805f-bd80e449ae7a",
   "metadata": {},
   "source": [
    "#### Comparison of quantitative variables distributions to normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23c907-9a6e-4086-bdc2-cc42dfedfcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12,10))\n",
    "axes = axes.flatten()\n",
    "plt.tight_layout()\n",
    "\n",
    "for i, col in enumerate(data[quantitative]):\n",
    "    ax = axes[i]\n",
    "    data[col].hist(ax=ax, bins=30, density=True, edgecolor='black')\n",
    "    mu, sigma = np.mean(data[col]), np.std(data[col])\n",
    "    x = np.linspace(min(data[col]), max(data[col]), 1000)\n",
    "    y = norm.pdf(x, mu, sigma)\n",
    "    ax.plot(x, y, 'r-')\n",
    "    ax.set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6026cb-47d3-428a-9859-e94515e76a82",
   "metadata": {},
   "source": [
    ">As we can see, *base* fits the normal distribution quite well. As well *age* and *duration_total* somehow can be approximated by the gaussian but this remains a disputed issue. It may seem that *bonus*, *overtime_pay* and *other* are also well described. However we can't determine this due to low resolution of these plots. So let's check more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd1204-93f2-46ec-b46b-153076e8cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(data, col, min, max):\n",
    "    return data[(data[col] > min) & (data[col] <= max)][col]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,5))\n",
    "axes = axes.flatten()\n",
    "plt.tight_layout()\n",
    "\n",
    "for i, col in enumerate(data[['bonus', 'overtime_pay', 'other']]):\n",
    "    ax = axes[i]\n",
    "    part = cut_data(data, col, 0, 22000)\n",
    "    part.hist(ax=ax, bins=25, density=True, edgecolor='black')\n",
    "    mu, sigma = np.mean(data[col]), np.std(data[col])\n",
    "    x = np.linspace(min(part), max(part), 1000)\n",
    "    y = norm.pdf(x, mu, sigma)\n",
    "    ax.plot(x, y, 'r-')\n",
    "    ax.set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34de39f-adff-42bf-9c77-8fab32f92e14",
   "metadata": {},
   "source": [
    ">After zooming in *bonus* and *overtime_pay* don't fit normal distribution. However *other* appears to be fitting it slightly, but we must take into account that we discarded values that equaled to $0$. Otherwise there would be no match between this variable and gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba0f42-fe4d-4fb7-a72c-553f51a2897d",
   "metadata": {},
   "source": [
    ">Let's check lognormal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee915e41-80b8-4fbe-ad2f-9f7df6a40732",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12,10))\n",
    "axes = axes.flatten()\n",
    "plt.tight_layout()\n",
    "\n",
    "for i, col in enumerate(data[quantitative]):\n",
    "    ax = axes[i]\n",
    "    data[col].hist(ax=ax, bins=30, density=True, edgecolor='black')\n",
    "    log_data = np.log(data[col][data[col] > 0])  # Ensure values > 0 for log\n",
    "    mu, sigma = np.mean(log_data), np.std(log_data)\n",
    "    x = np.linspace(min(data[col]), max(data[col]), 1000)\n",
    "    y = lognorm.pdf(x, s=sigma, scale=np.exp(mu))\n",
    "    ax.plot(x, y, 'r-', label='Lognormal fit')\n",
    "    ax.set_title(col)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7645219f-caaf-4f2a-95c0-52096bd3d363",
   "metadata": {},
   "source": [
    ">Only *other* follows logistic distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f33d84-bdf6-42db-9cce-ca5225c66584",
   "metadata": {},
   "source": [
    ">Let's check what is going on with qualitative variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba45f7-a8f7-4e6e-b260-d26d1efdfa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(data[qualitative]):\n",
    "    ax = axes[i]\n",
    "    data[col].value_counts(sort=False).plot(kind='bar', ax=ax)\n",
    "    ax.set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e213303-9d6f-43e0-bfb7-f11c9efba811",
   "metadata": {},
   "source": [
    ">Fitting distribution would make sense when it comes to *education* because the order is defined. However, it doesn't follow any distribution that I am aware of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5993cf6-61a1-4874-98f2-a40c27d709ee",
   "metadata": {},
   "source": [
    "## Task. 2 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536e58d-cf8d-48b8-aef1-9ff23deb7967",
   "metadata": {},
   "source": [
    ">Scaling the data because algorithms like KMeans use distance between points. Since each variable is on its own scale model would be more sensitive to variable with highest variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e8781-0fcb-403e-a1e4-f7526f1f70b7",
   "metadata": {},
   "source": [
    ">We have to do OneHotEncoding on unordered features because otherwise it would be misleading for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3331e8b-f0b7-4df3-9e40-bfd3becef585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered = quantitative + ['education']\n",
    "unordered = list(set(data.columns) - set(ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb1a33-391e-4219-9fe3-3de94bc160bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.set_output(transform='pandas')\n",
    "features_scaled = scaler.fit_transform(data[ordered])\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoder.set_output(transform='pandas')\n",
    "one_hot_features = encoder.fit_transform(data[unordered])\n",
    "\n",
    "data_scaled = pd.concat([features_scaled, one_hot_features], axis=1)  \n",
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aeb8de-08aa-43e6-b111-c259bf0c1bb8",
   "metadata": {},
   "source": [
    "Let's try different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0608308-7b3a-4a33-bd77-9fecb9a912f0",
   "metadata": {},
   "source": [
    ">Clustering metrics are not only sensitive to dataset but also to selected features. This applies directly to our dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81704335-aba8-43ea-944b-fc95c76aba3e",
   "metadata": {},
   "source": [
    ">Clustering whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c0eda-92d9-451a-af1d-7e304a4a67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    evaluate_KMeans(data_scaled, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30a67f-fa35-4387-a440-2fd17fc4535a",
   "metadata": {},
   "source": [
    ">Clustering two arbitrary chosen features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c2a5d-8abd-4288-bd04-cd1fe9c3cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    evaluate_KMeans(data_scaled[['duration_total', 'sex_2']], i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954ead4-9e9c-4fe7-9bf3-b3b93ccec7ea",
   "metadata": {},
   "source": [
    ">Thereâ€™s little value in clustering just to improve evaluation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3a950-a3ae-4ec7-aacf-dba7578b90f4",
   "metadata": {},
   "source": [
    ">We can try dimensionality reduction and examine results visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74006b7a-2999-4138-8ac0-074366d8ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.set_output(transform='pandas')\n",
    "reduced = pca.fit_transform(data_scaled)\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98160c-d94f-4e8c-98a1-00ad8bad9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(reduced, x='pca0', y='pca1', z='pca2')\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc51d15-f55b-4757-a4aa-8b3ac6fa2780",
   "metadata": {},
   "source": [
    ">It is hard to determine whether there are clusters. I can see something (plate and very closely a corner shape) but it can be only seen from a certain angle and is not clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a5f5e-97de-4192-89e6-ca4b6a3e81a8",
   "metadata": {},
   "source": [
    "> Let's try clustering it by KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293da80-d290-4d38-9b59-4c22a3a9320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_clustered = reduced.copy()\n",
    "reduced_clustered['cluster'] = KMeans(n_clusters=2).fit_predict(reduced)\n",
    "fig = px.scatter_3d(reduced_clustered, x='pca0', y='pca1', z='pca2', color='cluster')\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb69915-3401-4e94-9690-f7336df37909",
   "metadata": {},
   "source": [
    ">Unfortunately KMeans didn't pick up those clusters that i have seenðŸ˜¥. Maybe it was an illusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08f228-3901-4203-afd3-b046dfe7a078",
   "metadata": {},
   "source": [
    "> Let's try GaussianMixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf5b23-a9f9-4cb9-a5ba-746a0f84b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_clustered = reduced.copy()\n",
    "reduced_clustered['cluster'] = GaussianMixture(n_components=2, n_init=10).fit_predict(reduced)\n",
    "fig = px.scatter_3d(reduced_clustered, x='pca0', y='pca1', z='pca2', color='cluster')\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e2444-4953-424d-b6a5-873f58a2c223",
   "metadata": {},
   "source": [
    ">Maybe I wasn't wrong. Gaussian model almost identified what I had in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d1f58-7d52-481e-9423-0be1bef5bfbb",
   "metadata": {},
   "source": [
    ">But still they are very unclear. We can't be fully sure. We should plot all possible pairwise plots to get better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49ea64-8653-4c59-b414-5e788399c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc1acb-1595-4216-84c9-b58578bf9306",
   "metadata": {},
   "source": [
    ">There are no visible clusters. \\\n",
    ">We will train multiple models and pick one that performs the best, and then analyze it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21d8be-7431-4166-aa85-dc148eb43d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    evaluate_GMM(data_scaled, i, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac0cff-4402-419a-843c-80b4064b0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    evaluate_GMM(data_scaled, i, 'tied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989947c-a52e-40f7-a27d-4a0ff21f2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    evaluate_GMM(data_scaled, i, 'diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2211f02-f4db-482a-b714-2cd68bb507f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    evaluate_GMM(data_scaled, i, 'spherical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706bf924-ccbb-4d68-aeba-ee456a94051c",
   "metadata": {},
   "source": [
    ">Even though KMeans perfomed better than Gaussian Mixture model. I will stick to GMM just because it detected my illusive vision. \\\n",
    ">I will choose covariance_type='spherical' becaused it has the best scores across other GMMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa7838-6c7b-4f1f-9b2b-ef1710116091",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_plots_GMM(data_scaled, 2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38571c-449f-4908-b50b-428afca9b4ad",
   "metadata": {},
   "source": [
    "> Highest silhouette_score was for 3 clusters. We should check how would this model cluster the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809d854-47fa-4ac7-9bec-cd3c75b43748",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_clustered = reduced.copy()\n",
    "reduced_clustered['cluster'] = GaussianMixture(n_components=3, n_init=10, covariance_type='spherical').fit_predict(data_scaled)\n",
    "fig = px.scatter_3d(reduced_clustered, x='pca0', y='pca1', z='pca2', color='cluster')\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa21b37-fd19-430c-9900-d5f7251dca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled_clustered = data_scaled.copy()\n",
    "data_scaled_clustered['cluster'] = GaussianMixture(n_components=3, n_init=10, covariance_type='spherical').fit_predict(data_scaled)\n",
    "sns.pairplot(data_scaled_clustered, hue='cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531bd723-5ccb-4b11-ac5a-d0d60a1df277",
   "metadata": {},
   "source": [
    ">Therefore, Iâ€™d say that our data is not naturally clusterableâ€”or if it is, the structure is difficult to observe and these techniques donâ€™t yield any meaningful insights. However, it made me realize the importance of always asking: what is the goal of clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966e483-d8ee-4564-945d-ff11e61a626e",
   "metadata": {},
   "source": [
    ">Purely out of curiosity, let's take a look at how my elusive clustering appears on a feature pair plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc17b3-d2a1-4fd7-a3a2-3a5cf71d9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled_clustered = data_scaled.copy()\n",
    "data_scaled_clustered['cluster'] = GaussianMixture(n_components=2, n_init=10).fit_predict(reduced)\n",
    "sns.pairplot(data_scaled_clustered, hue='cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eaa2db-dce2-4f8b-9cbd-7c6988e02bae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b836dff-0260-4398-bfe7-ec6b27c39269",
   "metadata": {},
   "source": [
    "#### Convert data\n",
    "1 indicates higher education (<=2) \\\n",
    "0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55440c-ceea-4e0e-89ad-865e8b3e20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_scaled.drop(columns='education')\n",
    "y = (data['education'] <= 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf521e-efb9-425a-b924-a5e3f1990937",
   "metadata": {},
   "source": [
    ">Try different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e56a8-b0a3-45fe-9c34-2b11b277dab1",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bfb02-82e2-498b-af2d-6abc5073505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "print_short_classification_report(y, y_pred)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "feature_importances = model.coef_[0]\n",
    "show_feature_importance(feature_importances, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b82e60-1391-4cce-90d9-ddf20f2a3ede",
   "metadata": {},
   "source": [
    "### Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a347e-3d1d-454a-b5e0-19b0e83b9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(DecisionTreeClassifier())\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "print_short_classification_report(y, y_pred)\n",
    "model.fit(X, y)\n",
    "feature_importances = np.mean([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "show_feature_importance(feature_importances, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0916d2f-0ccd-4f8c-81da-5bb47411f14d",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a94ee5-f1ce-480e-90e5-6d5e7caa1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "print_short_classification_report(y, y_pred)\n",
    "\n",
    "model.fit(X, y)\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "show_feature_importance(model.feature_importances_, X.columns, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09987b0-c8e8-4058-87e1-1c83afc543aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_accuracies = cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3cdb0-3e12-4b43-9f74-c34c024d4046",
   "metadata": {},
   "source": [
    "### AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8b933-74f4-400f-a6b3-9fd404473f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier()\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "print_short_classification_report(y, y_pred)\n",
    "\n",
    "model.fit(X, y)\n",
    "show_feature_importance(model.feature_importances_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71686f-4f61-4319-81c2-0c72876966c4",
   "metadata": {},
   "source": [
    ">Thanks to `cross_val_predict` we were able to do cross validation and predict label for each data point as if that data point had been in the test set of a cross-validation fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2af9f-a424-463a-9e25-c895f872a3cd",
   "metadata": {},
   "source": [
    ">As we saw before the model that performed the best was RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14e994-ec21-4618-92b8-be687cb7bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1, len(RFC_accuracies) + 1), RFC_accuracies)\n",
    "plt.title('Comparison of RandomForestClassifier accuracies across folds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6399d5e-f73c-48e6-aaf1-add2179e659c",
   "metadata": {},
   "source": [
    ">Based on accuracies across folds we may predict that model is stable and has not been overfitted, and will perform quite well on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807bf20-f78d-419b-91e6-8cd401aceda0",
   "metadata": {},
   "source": [
    ">At the feature importance plot of RandomForestClassifier we can see that *base* and *duration_nominal* are the most significant variables. However when we look at feature importance plot of LogisticRegression we may see that some featues have negative importance, which indicates that they have negative influence on the final prediction. In this case, the higher *duration_nominal* the more likely it is that predicted education degree will be worse(>2). Absolute values of feature importances of both models look somewhat similar so we may suspect that RandomForestClassifier has the same dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314c72f-9c68-4db3-ae6e-e79ffb70c005",
   "metadata": {},
   "source": [
    "## Task 4. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda5b55-e7ee-4c88-a80c-74007b4a4ff6",
   "metadata": {},
   "source": [
    "Based on the task description, we can assume that the model should be highly interpretable, which strongly suggests using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bf34b-bcc7-41af-80d9-fde61fde56f6",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1703d901-a920-4ee7-b335-90f43e96b919",
   "metadata": {},
   "source": [
    ">We use scaled data in order to preserve numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685225b7-d437-4715-98e1-6717fb926bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_scaled.drop(columns='base')\n",
    "y = data['base']\n",
    "X_train_1, X_test_1, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train_1 = sm.tools.tools.add_constant(X_train_1)\n",
    "X_test_1 = sm.tools.tools.add_constant(X_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8450056-12d9-4321-82f1-37b7eb5d765b",
   "metadata": {},
   "source": [
    ">Train first model on all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45182bd9-82aa-4c6a-85f2-00a65ad3a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = sm.regression.linear_model.OLS(y_train, X_train_1)\n",
    "res_1 = model_1.fit()\n",
    "res_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba65bf-0175-4f2b-accc-0a0b2a47500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = res_1.predict(X_test_1)\n",
    "print('rmse:', root_mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3910484-d4e5-4d36-9562-47a90e2d3abe",
   "metadata": {},
   "source": [
    ">Only *sector* variable has t-value lower than 2 which indicates its insignificance. Based on table above we should discard only this feature. However it is worth looking into correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7861e-8c15-4212-8338-1b157f521d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(X_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a01cd-9466-4259-8339-8f2d500a1e2b",
   "metadata": {},
   "source": [
    ">We can see that *duration_total* and *age* are highly correlated as well as *duration_overtime* and *overtime_pay*. We expect that after removing one variable from each pair, our model's performance won't deteriorate significantly. Let's remove *duration_overtime* and *age*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deced32-e27e-4f72-a22e-4b47c2b7fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train_1.drop(columns=['duration_overtime', 'age', 'sector_2'])\n",
    "X_test_2 = X_test_1.drop(columns=['duration_overtime', 'age', 'sector_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705c9ca-c4ff-4003-89c0-81cab7a4c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = sm.regression.linear_model.OLS(y_train, X_train_2)\n",
    "res_2 = model_2.fit()\n",
    "res_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bd870-3604-49cb-93f3-58c1399e48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = res_2.predict(X_test_2)\n",
    "print('rmse:', root_mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdce90d-8ed0-4485-a4bf-916df845ec4f",
   "metadata": {},
   "source": [
    ">After deletion of three variables out model perform slightly worse than before. We can try deleting 2 more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab21c7b-fb05-437f-8908-8042e731091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = X_train_2.drop(columns=['section_07_3', 'sex_2'])\n",
    "X_test_3 = X_test_2.drop(columns=['section_07_3', 'sex_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2df6a3-5bd6-4988-a5b9-92f39d827ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = sm.regression.linear_model.OLS(y_train, X_train_3)\n",
    "res_3 = model_3.fit()\n",
    "res_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602ea8b-63c4-4e8b-96d6-39e8ed4aaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = res_3.predict(X_test_3)\n",
    "print('rmse:', root_mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39fc08-f6a2-47de-8c0d-4bc9e090deee",
   "metadata": {},
   "source": [
    ">There was a slight decline in prediction accuracy. It was so small that it can be omittable. Let's go even futher and delete 2 more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfc819-96b5-469d-b15e-bd56c86b6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4 = X_train_3.drop(columns=['duration_entity', 'contract_2'])\n",
    "X_test_4 = X_test_3.drop(columns=['duration_entity', 'contract_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434745d-eea9-4621-bbc5-7a6c3efce5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = sm.regression.linear_model.OLS(y_train, X_train_4)\n",
    "res_4 = model_4.fit()\n",
    "res_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c96a93-5876-48d1-8b85-7e165f2eb18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = res_4.predict(X_test_4)\n",
    "print('rmse:', root_mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e33778-f5e3-4d31-96ce-d61ce2ff5d68",
   "metadata": {},
   "source": [
    ">Both RMSE and R squared metric decreased notably. So we will stick to the previous model no. 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30bfc6-31b6-4444-aede-c540590b0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa32c5b-ce5d-47ce-8236-81cd6ee7e697",
   "metadata": {},
   "source": [
    ">Features used in model_3: \\\n",
    "bonus - moderate positive influence - increase in bonus increases salary \\\n",
    "overtime_pay - more significant then bonus in the same way \\\n",
    "other - highest positive influence \\\n",
    "duration_total - very high positive influence \\\n",
    "duration_entity - lowest positive influence across all variables, barerly noticable \\\n",
    "duration_nominal - slightly lower positive influence than other variable \\\n",
    "education - strongest negative impact. But since education levels were inverted the lower the education the variable the higher the total income. It is the most significant variable in our model. \\\n",
    "section_07_2 - negative impact, but still quite noticable\n",
    "contract_2\t- negative coefficient, doesn't affect model that much"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
